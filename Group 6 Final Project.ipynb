{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1ogme9BJeHb2IZ6UREavUorF--nnxoWCYAAi8AZ4Q5jQ/edit?usp=sharing) and [grading rubric](https://docs.google.com/document/d/1XI9Yq_e-U-D3iH4jTPAtNteeP2Q9mtJ9NKbePWKeN_g/edit?usp=sharing)\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import declarative_base\n",
    "import subprocess\n",
    "import psycopg2\n",
    "from geoalchemy2 import WKTElement, Geometry\n",
    "from shapely.geometry import Point\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"qmf4vTidE7TMehCHe78KV7SIM\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/resource/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"Group6Finalproject\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"  \n",
    "DB_PORT = \"5432\" \n",
    "\n",
    "#DB_URL = f\"postgresql+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY & DATA_DIR exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()\n",
    "if not (DATA_DIR/\"data_cleaned\").exists():    \n",
    "    (DATA_DIR/\"data_cleaned\").mkdir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b18f12-c0ce-4b9c-adc1-805703edc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url, force=False):\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(..., f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b274b23",
   "metadata": {},
   "source": [
    "## Zillow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data():\n",
    "    df = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "    #Only need New York\n",
    "    df = df[df['City']=='New York']\n",
    "    #Remove unneeded columns\n",
    "    df.drop(columns=['RegionID', 'SizeRank','RegionType','StateName','State','City','Metro','CountyName'],inplace=True)\n",
    "    \n",
    "    # Normalize column names used later\n",
    "    column_name_mapping ={\n",
    "    '2023-01-31': 'Jan_2023', '2023-02-28': 'Feb_2023', '2023-03-31': 'Mar_2023',\n",
    "    '2023-04-30': 'Apr_2023', '2023-05-31': 'May_2023', '2023-06-30': 'Jun_2023',\n",
    "    '2023-07-31': 'Jul_2023', '2023-08-31': 'Aug_2023', '2023-09-30': 'Sep_2023',\n",
    "    '2023-10-31': 'Oct_2023', '2023-11-30': 'Nov_2023', '2023-12-31': 'Dec_2023',\n",
    "    '2024-01-31': 'Jan_2024', \n",
    "    }\n",
    "    \n",
    "    df.rename(columns=column_name_mapping, inplace=True) \n",
    "    df.rename(columns={'RegionName': 'zip_code'}, inplace=True)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != 'zip_code':\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "    df['zip_code'] = df['zip_code'].astype(\"string\")\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    \n",
    "    df1['mean'] = df1.iloc[:, 1:].mean(axis=1, skipna=True)\n",
    "    \n",
    "    clean_columns = ['zip_code', 'Mar_2023', 'Apr_2023', 'May_2023', \n",
    "                 'Jun_2023', 'Jul_2023', 'Aug_2023', 'Sep_2023', 'Oct_2023',\n",
    "                 'Nov_2023', 'Dec_2023', 'Jan_2024','mean']\n",
    "    df1 = df1[clean_columns]\n",
    "    \n",
    "    df1.iloc[:,1:] = df1.iloc[:,1:].fillna(df.iloc[:,1:].mean())\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data = load_and_clean_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623cf820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc08ab64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c280d1f",
   "metadata": {},
   "source": [
    "## Zipcode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    zipcode_data = gpd.read_file(zipcode_datafile)\n",
    "    zipcode_data = zipcode_data[['ZIPCODE', 'geometry']]\n",
    "    zipcode_data = zipcode_data.to_crs(epsg=4326)\n",
    "    zipcode_data = zipcode_data.rename(columns={'ZIPCODE': 'zipcode'})\n",
    "    zipcode_data = zipcode_data.dropna()\n",
    "    \n",
    "    return zipcode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f70302",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b12b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be84ae35",
   "metadata": {},
   "source": [
    "## Tree Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    url=f\"{BASE_NYC_DATA_URL}{NYC_DATA_TREES}?$$app_token={NYC_DATA_APP_TOKEN}&$limit=10000\"\n",
    "    filename=download_nyc_geojson_data(url)\n",
    "    df=gpd.read_file(filename)\n",
    "    \n",
    "    # To keep the necessary columns\n",
    "    df_selected=df[['tree_id','zipcode','address','health','zip_city','spc_common','status','sidewalk','borocode','block_id','geometry']]\n",
    "    \n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df_selected=df_selected.dropna()\n",
    "    \n",
    "    # Convert column names to lowercase\n",
    "    df_selected.columns = [col.lower() for col in df_selected.columns]\n",
    "    \n",
    "    # Change the SRID to a specific value (EPSG 4326 - WGS 84)\n",
    "    df_selected = df_selected.to_crs(epsg=4326)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data = download_and_clean_tree_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ff49f-a18b-4fc0-8da6-6834a10d11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "source": [
    "## NYC Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06882a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    \n",
    "    BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/resource/\"\n",
    "    NYC_DATA_311 = \"erm2-nwe9.json\"\n",
    "    \n",
    "    \n",
    "    data_url = BASE_NYC_DATA_URL + NYC_DATA_311\n",
    "    columns = \"unique_key,created_date,closed_date,complaint_type,incident_zip,latitude,longitude\"\n",
    "    start_date = \"2023-03-01\"\n",
    "    end_date = \"2024-02-29\"\n",
    "    limit = 50000\n",
    "    offset = 0\n",
    "    total_rows = 0\n",
    "    headers = {\"X-App-Token\": NYC_DATA_APP_TOKEN}\n",
    "    all_data = []\n",
    "    \n",
    "    while True:\n",
    "        query = f\"$select={columns}&$where=created_date >= '{start_date}T00:00:00.000' AND created_date <= '{end_date}T23:59:59.999' AND latitude IS NOT NULL&$limit={limit}&$offset={offset}\"\n",
    "        paginated_url = f\"{data_url}?{query}\"\n",
    "        response = requests.get(paginated_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                all_data.extend(data)\n",
    "                total_rows += len(data)\n",
    "                offset += limit\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df = df.rename(columns={'incident_zip':'zip_code'})\n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"EPSG:4326\"\n",
    "    )\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data = download_and_clean_311_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cbfabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349fbdd-67d0-40a4-97a0-d9b8c8ec8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_new_postgis_database(username, db_name, password):\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db_name, \n",
    "        user=username,\n",
    "        password='postgres',  \n",
    "        host='localhost',   \n",
    "        port='5432'         \n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.close()\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ed80d-7b60-484f-a123-23b673b0f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_new_postgis_database(DB_USER, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d72390-3c2d-4856-82c0-3284e8ccb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac07405-dc2b-47af-9dad-6a9b94d2b34c",
   "metadata": {},
   "source": [
    "#### Option 1: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d0cc6-74b3-4d35-a454-57f647c9f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using SQL (as opposed to SQLAlchemy), define the SQL statements to create your 4 tables.\n",
    "# You may be creating more tables depending on how you're setting up your constraints/relationships\n",
    "# or if you're completing the extra credit.\n",
    "\n",
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS zip_codes (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    zipcode CHAR(5),\n",
    "    geometry GEOMETRY (Polygon,4326)\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS NYC_311 (\n",
    "    unique_key VARCHAR(50) PRIMARY KEY,\n",
    "    created_date VARCHAR(50),\n",
    "    closed_date VARCHAR(50),\n",
    "    complaint_type VARCHAR(100),\n",
    "    zip_code VARCHAR(5),\n",
    "    latitude VARCHAR(50),\n",
    "    longitude VARCHAR(50),\n",
    "    geometry GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS trees;\n",
    "CREATE TABLE IF NOT EXISTS trees (\n",
    "    tree_id VARCHAR(50) PRIMARY KEY,\n",
    "    zipcode VARCHAR(10),\n",
    "    address VARCHAR(255),\n",
    "    health VARCHAR(255), \n",
    "    zip_city VARCHAR(255), \n",
    "    spc_common VARCHAR(255),\n",
    "    status VARCHAR(255),\n",
    "    sidewalk VARCHAR(255),\n",
    "    borocode VARCHAR(10),\n",
    "    block_id VARCHAR(255),\n",
    "    geometry GEOMETRY (Point,4326)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS rents\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    zip_code CHAR(5),\n",
    "    Jan_2023 FLOAT,\n",
    "    Feb_2023 FLOAT,\n",
    "    Mar_2023 FLOAT,\n",
    "    Apr_2023 FLOAT,\n",
    "    May_2023 FLOAT,\n",
    "    Jun_2023 FLOAT,\n",
    "    Jul_2023 FLOAT,\n",
    "    Aug_2023 FLOAT,\n",
    "    Sep_2023 FLOAT,\n",
    "    Oct_2023 FLOAT,\n",
    "    Nov_2023 FLOAT,\n",
    "    Dec_2023 FLOAT,\n",
    "    Jan_2024 FLOAT,\n",
    "    mean FLOAT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d86f6-ff6e-4bb8-8fa2-df0d4282e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e968d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(f\"dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD}\")\n",
    "cur = conn.cursor()\n",
    "with cur:\n",
    "    cur.execute(ZIPCODE_SCHEMA)\n",
    "    cur.execute(NYC_311_SCHEMA)\n",
    "    cur.execute(NYC_TREE_SCHEMA)\n",
    "    cur.execute(ZILLOW_SCHEMA)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66af67-afb8-4f0d-bb57-552972f8e4b8",
   "metadata": {},
   "source": [
    "#### Option 1: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e37800-cd95-44b5-9c21-eb7ac2b2e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(tablename_to_dataframe):\n",
    "    # write INSERT statements or use pandas/geopandas to write SQL\n",
    "    engine = create_engine(DB_URL)\n",
    "    \n",
    "    for tablename, dataframe in tablename_to_dataframe.items():\n",
    "        if 'geometry' in dataframe.columns:\n",
    "            temp_df = dataframe.copy()\n",
    "            temp_df['the_geom'] = temp_df['geometry'].apply(lambda geom: WKTElement(geom.wkt, srid=4326) if geom is not None else None)\n",
    "            temp_df.drop('geometry',axis=1,inplace=True)\n",
    "            temp_df.to_sql(tablename, engine, if_exists='replace', index=False, \n",
    "                           dtype={'the_geom': Geometry('GEOMETRY', srid=4326)}) \n",
    "            \n",
    "        else:\n",
    "            dataframe.to_sql(tablename, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f042f5-8270-477d-929a-872f7d9a0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename_to_dataframe = {\n",
    "    \"zipcodes\": geodf_zipcode_data,\n",
    "    \"complaints\": geodf_311_data,\n",
    "    \"trees\": geodf_tree_data,\n",
    "    \"rents\": df_zillow_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d052c50-1e43-4356-bcac-4f5abc7e714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(tablename_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf42213",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb63b553-0c64-4da8-9fc7-41555d89d853",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce8548-4aba-4bf9-992c-dedd0f249db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, \"w\") as file:\n",
    "        file.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7e12b-e251-4f08-8dc5-601db30c2089",
   "metadata": {},
   "source": [
    "### Query 1: Incidents per Zip Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605e6f3-ec42-4a8b-833c-5138c14b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"complains_per_Zip_Code.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT zip_code, COUNT(*) AS complaint_count\n",
    "FROM complaints\n",
    "WHERE created_date >= '2023-03-01' AND created_date <= '2024-02-29'\n",
    "GROUP BY zip_code\n",
    "ORDER BY complaint_count DESC;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce044adf-ecdf-4237-9b20-b7cdaaab0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b2c3d-8961-4c7e-8eb1-fc973d0ab9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00b33c",
   "metadata": {},
   "source": [
    "## Query 2: Green Areas by Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR / \"Top10_Zip_Codes_by_trees.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS tree_count\n",
    "FROM trees\n",
    "GROUP BY zipcode\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10306', 2355)\n",
      "('11230', 1545)\n",
      "('10466', 1400)\n",
      "('11375', 1215)\n",
      "('11215', 1172)\n",
      "('10312', 1115)\n",
      "('11426', 1107)\n",
      "('11105', 1056)\n",
      "('11218', 1011)\n",
      "('11372', 970)\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f302a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75223ce5-6ab5-4613-b6af-fa8e33bcc7d5",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcfed-ddbb-4908-a60e-ed7cbc6d5b00",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e2cde-e43b-407b-ab93-ff85a2dba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80755f-d1e1-4e53-8ef8-f5295c59a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query your database for the data needed.\n",
    "    # You can put the data queried into a pandas/geopandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2632a-b516-4a6e-8b67-97116ab6fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
